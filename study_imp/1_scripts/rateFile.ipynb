{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Summary file and Rating files (Free-route)\n",
    "1. rename cyoa spr .prolific to .txt files\n",
    "2. grab from the spr file, the story map, and the prolific survey to make the summary file\n",
    "3. compute additional information and output to another summary file; mannually paste to summary file.\n",
    "4. create recall text files for processing and causality rating files (with story files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#1. this is to change the .prolific files to .txt files\n",
    "import xianfunc as xf\n",
    "\n",
    "fpath = '../rate_importance/spr_data/'\n",
    "filelist = xf.grab_all(fpath,'sona')#\n",
    "print(len(filelist))\n",
    "targlist = xf.replace_str(filelist,'.sona','.txt')\n",
    "xf.rename_files(fpath,filelist,targlist)\n",
    "\n",
    "filelist = xf.grab_all(fpath,'txt')\n",
    "n_size = str(len(filelist))\n",
    "print(n_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyoa_monthy-free_end2_xli239.txt\n",
      "['1', '2', '3', '13_2', '770', '771', '772', '773', '774', '790']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Excel file saved'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. make the summary file via grabing info from story map, cyoa spr file and the survey file\n",
    "\n",
    "v = 4500 #uniq version number (alice-free=1000,alice-yoke=2000,alice-pasv=3000,monthy-free=4000)\n",
    "sum_data = xf.init_dict(keylist=['sub','ID','pid','end_version','storyline','choice_vec','story_route','time_step','story','recall','story_word_count','recall_word_count'])\n",
    "\n",
    "count=0\n",
    "for file in filelist:\n",
    "    print(file)\n",
    "    count+=1\n",
    "    completed = xf.grab_all('../rate_importance/spr_data/completed/','.txt')\n",
    "    sub_num = count+len(completed)\n",
    "    uniq_id = sub_num+v+len(completed)\n",
    "    version = file.split('.')[0].split('_')[1]+ '_'+ file.split('.')[0].split('_')[2]\n",
    "    subj_id = file.split('.')[0].split('_')[-1]\n",
    "\n",
    "    data = xf.read_text(fpath+file,sep='\\n',header='col1')\n",
    "    spr_end = data['ending_version'][0]\n",
    "    print(data['story_path'])\n",
    "    if '13_2' in data['story_path']:\n",
    "        spr_sl = 3\n",
    "    elif '14_2' in data['story_path']:\n",
    "        spr_sl = 2\n",
    "    elif '14_1' in data['story_path']:\n",
    "        spr_sl=1\n",
    "    else:\n",
    "        print('check story_path for storyline')\n",
    "    spr_time_step = data['time_step'][1:]\n",
    "    tstep = []\n",
    "    for i in spr_time_step:\n",
    "        if 'enter' in i or 'click' in i:\n",
    "            tstep.append(float(i.split(':')[-1]))\n",
    "    spr_time_step = ','.join([str(i) for i in tstep])\n",
    "    spr_choice_vec = ','.join(data['choice_vec'])\n",
    "    spr_story_path = ','.join(data['story_path'])\n",
    "    spr_story_text = ' '.join(data['story_text'])\n",
    "    spr_recall = ' '\n",
    "    \n",
    "    sum_data['sub'].append(str(sub_num))\n",
    "    sum_data['ID'].append(str(uniq_id))\n",
    "    sum_data['pid'].append(subj_id)\n",
    "    sum_data['end_version'].append(str(spr_end))\n",
    "    sum_data['storyline'].append(str(spr_sl))\n",
    "    sum_data['choice_vec'].append(spr_choice_vec)\n",
    "    sum_data['story_route'].append(spr_story_path)\n",
    "    sum_data['time_step'].append(spr_time_step)\n",
    "    sum_data['story'].append(spr_story_text)\n",
    "    sum_data['recall'].append(spr_recall)\n",
    "    sum_data['story_word_count'].append(len(spr_story_text.split(' ')))\n",
    "    sum_data['recall_word_count'].append(len(spr_recall.split(' ')))\n",
    "    \n",
    "outname = 'summary_'+version.split('_end')[0]+'_n'+n_size+'_rate-importance.xlsx'\n",
    "xf.write_dict_samelen(sum_data,outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Excel xlsx file; not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m exclude \u001b[38;5;241m=\u001b[39m []\u001b[38;5;66;03m#2,3,4,6]\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,subjnum):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#get subj story info ('scene_lab','event_lab','scene_text') from  map_cols(scene_lab,event_lab,story) & sum_cols(sub,ID,story_route) \u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     subj,data \u001b[38;5;241m=\u001b[39m xf\u001b[38;5;241m.\u001b[39mcyoa_subj_paths(mapfile,sumfile,subj_ind\u001b[38;5;241m=\u001b[39mind,map_cols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m],sum_cols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m7\u001b[39m])\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ind\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude: \n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(subj)\n",
      "File \u001b[0;32m~/Desktop/study_imp/1_scripts/xianfunc.py:4030\u001b[0m, in \u001b[0;36mcyoa_subj_paths\u001b[0;34m(mapfile, sumfile, subj_ind, map_cols, sum_cols, keynames)\u001b[0m\n\u001b[1;32m   4028\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcyoa_subj_paths\u001b[39m(mapfile,sumfile,subj_ind,map_cols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m7\u001b[39m],sum_cols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m6\u001b[39m],keynames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscene_label\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_label\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscene_text\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m   4029\u001b[0m     \u001b[38;5;66;03m#free route: get map and subject data \u001b[39;00m\n\u001b[0;32m-> 4030\u001b[0m     alldat,allrow \u001b[38;5;241m=\u001b[39m read_rows(read_table(sumfile),sum_cols)  \n\u001b[1;32m   4031\u001b[0m     rowlist \u001b[38;5;241m=\u001b[39m [row \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m allrow]    \n\u001b[1;32m   4032\u001b[0m     subjrow \u001b[38;5;241m=\u001b[39m allrow[rowlist[subj_ind]]    \n",
      "File \u001b[0;32m~/Desktop/study_imp/1_scripts/xianfunc.py:2395\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(infile, sheet)\u001b[0m\n\u001b[1;32m   2385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_table\u001b[39m(infile,sheet\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   2386\u001b[0m     \u001b[38;5;66;03m#infile specifies the name of the file and its path\u001b[39;00m\n\u001b[1;32m   2387\u001b[0m     \u001b[38;5;66;03m#example use:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2392\u001b[0m             \u001b[38;5;66;03m#    row_counter+=1\u001b[39;00m\n\u001b[1;32m   2393\u001b[0m             \u001b[38;5;66;03m#    vec = table.row_values(row)\u001b[39;00m\n\u001b[1;32m   2394\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxlrd\u001b[39;00m\n\u001b[0;32m-> 2395\u001b[0m     data \u001b[38;5;241m=\u001b[39m xlrd\u001b[38;5;241m.\u001b[39mopen_workbook(infile)\n\u001b[1;32m   2396\u001b[0m     table \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msheets()[sheet\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   2397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xlrd/__init__.py:170\u001b[0m, in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# We have to let unknown file formats pass through here, as some ancient\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# files that xlrd can parse don't start with the expected signature.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_format \u001b[38;5;129;01mand\u001b[39;00m file_format \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XLRDError(FILE_FORMAT_DESCRIPTIONS[file_format]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; not supported\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    172\u001b[0m bk \u001b[38;5;241m=\u001b[39m open_workbook_xls(\n\u001b[1;32m    173\u001b[0m     filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m    174\u001b[0m     logfile\u001b[38;5;241m=\u001b[39mlogfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m     ignore_workbook_corruption\u001b[38;5;241m=\u001b[39mignore_workbook_corruption,\n\u001b[1;32m    183\u001b[0m )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bk\n",
      "\u001b[0;31mXLRDError\u001b[0m: Excel xlsx file; not supported"
     ]
    }
   ],
   "source": [
    "#3 getting subject specific rating files (story, recall, causal)\n",
    "\n",
    "import xianfunc as xf\n",
    "subjnum = 1 #int(n_size)     \n",
    "sumfile = './summary_monthy-free_n1_rate-importance.xlsx'\n",
    "mapfile = './monthy_map.xlsx'\n",
    "out_rootdir = '../rate_importance/rate_free/' \n",
    "exclude = []#2,3,4,6]\n",
    "\n",
    "for ind in range(0,subjnum):\n",
    "    #get subj story info ('scene_lab','event_lab','scene_text') from  map_cols(scene_lab,event_lab,story) & sum_cols(sub,ID,story_route) \n",
    "    subj,data = xf.cyoa_subj_paths(mapfile,sumfile,subj_ind=ind,map_cols=[2,1,3],sum_cols=[1,2,7])\n",
    "    if ind+1 not in exclude: \n",
    "        print(subj)\n",
    "        #group data by events while singling out choice options\n",
    "        cutted,cut_by = xf.group_cut(data['scene_text'],data['scene_label'],'_')\n",
    "        group_by_new = xf.group_by_both_list(data['event_label'],cut_by)\n",
    "        data['event_num'] = group_by_new\n",
    "        grouped_data,n_groups = xf.group_dict(data,'event_num')\n",
    "        simp,full = xf.merge_ioflist_in_data(grouped_data)\n",
    "\n",
    "        #output the subject-specific story events file\n",
    "        outfile = out_rootdir +subj+'_rate-events.xlsx' \n",
    "        head = ['event','event_lab','scenes','story_texts','rate_importance','rate_saliency']\n",
    "        conv = ['event_num','event_label','scene_label','scene_text']\n",
    "        conv2head_ind = [0,1,2,3]\n",
    "        form = [[4],[60],[3,4],[2,3]] #col,width, col-wrap, col-hide\n",
    "        xf.write_dict_samelen(simp,outfile, header=head, convert=conv, dict_ind=conv2head_ind, set_format=form)\n",
    "        \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
